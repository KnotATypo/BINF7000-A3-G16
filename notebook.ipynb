{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55f5f372678b15bb",
   "metadata": {},
   "source": [
    "data = anndata.read_h5ad('data/Group_6.h5ad')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2862c01fb99bdde3",
   "metadata": {},
   "source": [
    "# data.X.toarray()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Renaming \"CD8+/CD45RA+ Naive Cytotoxic\" to \"CD8+/CD45RA+\" so it is more inline with other names and doesn't cause issues on graphs",
   "id": "5ed6e2233a3999d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.obs[\"cell-types\"] = data.obs[\"cell-types\"].replace(\"CD8+/CD45RA+ Naive Cytotoxic\", \"CD8+/CD45RA+\")",
   "id": "4aeb5d3f3573d242",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "656c34cf03975d86",
   "metadata": {},
   "source": [
    "# We will record the original cell type counts to make sure QC doesn't disproportionately remove any cell types\n",
    "original_cell_type_counts = data.obs[\"cell-types\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b05e60e7a8fb9b44",
   "metadata": {},
   "source": [
    "We don't want to include genes that are expressed in very few cells, as they are unlikely to provide useful information for downstream analysis.\n",
    "We can start with a general look at how many cells express each gene."
   ]
  },
  {
   "cell_type": "code",
   "id": "80421b04ddca2aa3",
   "metadata": {},
   "source": [
    "cells_per_gene = (data.X.toarray() > 0).sum(axis=0)\n",
    "sns.displot(cells_per_gene)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f5599557a6416f5",
   "metadata": {},
   "source": [
    "To get a better idea of how many genes would be removed at different thresholds, we can plot the cumulative number of genes that would be removed as we increase the minimum cell threshold."
   ]
  },
  {
   "cell_type": "code",
   "id": "a91f7d6dfe3bf4c",
   "metadata": {},
   "source": [
    "cumsum = np.cumsum(np.bincount(cells_per_gene))\n",
    "\n",
    "removed = []\n",
    "for m in range(1, 20):\n",
    "    removed.append(int(cumsum[m]))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(1, 20), removed)\n",
    "plt.xlabel(\"Minimum cells required per gene\")\n",
    "plt.ylabel(\"Number of genes removed\")\n",
    "plt.title(\"Genes removed vs minimum cells threshold\")\n",
    "plt.xticks(range(1, 20))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa8bef413bbc20f3",
   "metadata": {},
   "source": [
    "The inflection point seems to be around 3-5 cells, so we will err on the side of caution and filter out genes that are expressed in fewer than 3 cells. Lets check how many genes that removes."
   ]
  },
  {
   "cell_type": "code",
   "id": "1708f16758c866b3",
   "metadata": {},
   "source": [
    "before = data.shape[1]\n",
    "sc.pp.filter_genes(data, min_cells=3)\n",
    "print(\"Genes removed:\", before - data.shape[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "338d25cc5109e8d0",
   "metadata": {},
   "source": [
    "Next we can look at the distribution of how many genes are detected per cell to identify potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "id": "50e1a68585a8ecc6",
   "metadata": {},
   "source": [
    "genes_per_cell = (data.X.toarray() > 0).sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(genes_per_cell, kde=True)\n",
    "plt.title('Total Reads per Cell')\n",
    "plt.xlabel('Total Reads')\n",
    "plt.ylabel('Number of Cells')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f93ac6de8a9f045d",
   "metadata": {},
   "source": [
    "Let's use the median absolute deviation (MAD) to identify outlier genes that are expressed in an unusually high or low number of cells."
   ]
  },
  {
   "cell_type": "code",
   "id": "d41a1702eeba097",
   "metadata": {},
   "source": [
    "median = pd.Series(genes_per_cell).median()\n",
    "mad = pd.Series((genes_per_cell - median)).abs().median()\n",
    "upper_bound = median + 3 * mad\n",
    "lower_bound = median - 3 * mad\n",
    "\n",
    "data_filtered = data[genes_per_cell > lower_bound, :]\n",
    "data_filtered = data_filtered[(data_filtered.X.toarray() > 0).sum(axis=1) < upper_bound, :]\n",
    "print(\"Percent of cells removed by filtering:\", 100 * (1 - data_filtered.shape[0] / data.shape[0]))\n",
    "sns.displot((data_filtered.X.toarray() > 0).sum(axis=1), kde=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ceee18e4dccfd251",
   "metadata": {},
   "source": [
    "We are left with a cleaner dataset without the long tail of outlier cells which would likely skew downstream analyses, while only removing about 11% of the cells."
   ]
  },
  {
   "cell_type": "code",
   "id": "cda39f479304d861",
   "metadata": {},
   "source": [
    "original_cell_type_counts.plot(kind='bar', color='orange', label='Original', position=0)\n",
    "after_qc_counts = data_filtered.obs[\"cell-types\"].value_counts()\n",
    "after_qc_counts.plot(kind='bar', color='blue', label='After QC', position=1)\n",
    "\n",
    "percent_drop = 100 * (original_cell_type_counts - after_qc_counts) / original_cell_type_counts\n",
    "for i, v in enumerate(percent_drop):\n",
    "    plt.text(i, after_qc_counts[i] + 0.5, f\"{v:.1f}%\", ha='right', fontsize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "16a58de606b93355",
   "metadata": {},
   "source": [
    "There is a clear bias against the Dendritic cells, which had a much higher percentage of cells removed compared to the other cell types. We can investigate this further by plotting the distribution of genes detected per cell for each cell type."
   ]
  },
  {
   "cell_type": "code",
   "id": "51081076a81878ac",
   "metadata": {},
   "source": [
    "cell_types = data.obs[\"cell-types\"].unique()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.title('Total Reads per Cell by Cell Type')\n",
    "plt.xlabel('Total Reads')\n",
    "plt.ylabel('Percent of Cells')\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    cell_type_indexes = data.obs[data.obs[\"cell-types\"] == cell_type].index\n",
    "    genes_per_cell = (data[cell_type_indexes].X.toarray() > 0).sum(axis=1)\n",
    "\n",
    "    sns.histplot(genes_per_cell, kde=True, label=cell_type, stat=\"percent\", bins=60)\n",
    "\n",
    "plt.legend([ct for ct in cell_types])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d06811c1ea8ba1ef",
   "metadata": {},
   "source": [
    "There is a clear distrbution difference in the Dendritic cells compared to the other cell types. To account for this, we can apply cell type specific QC thresholds based on the MAD for each cell type individually."
   ]
  },
  {
   "cell_type": "code",
   "id": "35361e691f5753f5",
   "metadata": {},
   "source": [
    "filtered_data = []\n",
    "for ct in cell_types:\n",
    "    genes_per_cell = (data[data.obs[\"cell-types\"] == ct].X.toarray() > 0).sum(axis=1)\n",
    "    median = pd.Series(genes_per_cell).median()\n",
    "    mad = pd.Series((genes_per_cell - median)).abs().median()\n",
    "    upper_bound = median + 3 * mad\n",
    "    lower_bound = median - 3 * mad\n",
    "    print(ct, \"lower bound:\", lower_bound, \"upper bound:\", upper_bound)\n",
    "\n",
    "    ct_filtered = data[data.obs[\"cell-types\"] == ct][(genes_per_cell > lower_bound) & (genes_per_cell < upper_bound), :]\n",
    "    filtered_data.append(ct_filtered)\n",
    "\n",
    "data_filtered_per_cell = anndata.concat(filtered_data)\n",
    "print(\"Percent of cells removed by filtering:\", 100 * (1 - data_filtered_per_cell.shape[0] / data.shape[0]))\n",
    "\n",
    "sns.displot((data_filtered_per_cell.X.toarray() > 0).sum(axis=1), kde=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "591387c0f1175ab8",
   "metadata": {},
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "# First subplot\n",
    "original_cell_type_counts.plot(kind='bar', color='orange', label='Original', ax=axes[0], position=0)\n",
    "after_qc_counts = data_filtered_per_cell.obs[\"cell-types\"].value_counts()\n",
    "after_qc_counts.plot(kind='bar', color='blue', label='After QC', ax=axes[0], position=1)\n",
    "\n",
    "percent_drop = 100 * (original_cell_type_counts - after_qc_counts) / original_cell_type_counts\n",
    "for i, v in enumerate(percent_drop):\n",
    "    axes[0].text(i, after_qc_counts[i] + 0.5, f\"{v:.1f}%\", ha='right', fontsize=10)\n",
    "\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Cell Type Counts Before and After QC (Per Cell)\")\n",
    "\n",
    "# Second subplot\n",
    "original_cell_type_counts.plot(kind='bar', color='orange', label='Original', ax=axes[1], position=0)\n",
    "after_qc_counts = data_filtered.obs[\"cell-types\"].value_counts()\n",
    "after_qc_counts.plot(kind='bar', color='blue', label='After QC', ax=axes[1], position=1)\n",
    "\n",
    "percent_drop = 100 * (original_cell_type_counts - after_qc_counts) / original_cell_type_counts\n",
    "for i, v in enumerate(percent_drop):\n",
    "    axes[1].text(i, after_qc_counts[i] + 0.5, f\"{v:.1f}%\", ha='right', fontsize=10)\n",
    "\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Cell Type Counts Before and After QC (Overall)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bca95c97f7018502",
   "metadata": {},
   "source": [
    "The filtering based on cell type specific thresholds does a much better job of preserving the original cell type proportions, while still removing a similar overall percentage of cells. This should lead to more balanced downstream analyses."
   ]
  },
  {
   "cell_type": "code",
   "id": "697bc0652b8eaf41",
   "metadata": {},
   "source": [
    "data = data_filtered\n",
    "# Setting up dataframe for training\n",
    "labeled_df = pd.DataFrame(data.X.toarray(), columns=data.var_names)\n",
    "labeled_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# I'm not married to any particular metric here, so this can be changed if desired\n",
    "def score(predictions, truths):\n",
    "    return {\"balanced accuracy\": balanced_accuracy_score(truths, predictions),\n",
    "            \"f1\": f1_score(truths, predictions, average='weighted')}"
   ],
   "id": "260a83cad3847a38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model and print metrics and confusion matrix.\n",
    "\n",
    "    :param model:\n",
    "    :param X_train:\n",
    "    :param Y_train:\n",
    "    :param X_test:\n",
    "    :param Y_test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    predictions_train = model.predict(X_train)\n",
    "    metrics_train = score(predictions_train, Y_train)\n",
    "\n",
    "    predictions_test = model.predict(X_test)\n",
    "    metrics_test = score(predictions_test, Y_test)\n",
    "\n",
    "    for metric in metrics_train.keys():\n",
    "        print(f\"{metric} - Train: {metrics_train[metric]:.4f}, Test: {metrics_test[metric]:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(Y_test, predictions_test, labels=model.classes_, normalize=\"true\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.grid(False)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "id": "66c372f4b6b35caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Y = data.obs[\"cell-types\"].to_numpy()\n",
    "X = labeled_df"
   ],
   "id": "3f4599772107de10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Reduce the features using mutual information otherwise it crashes due to memory issues.\n",
    "This particular method was chosen as others like correlation based feature selection require O(n^2) memory which is infeasible for this dataset.\n",
    "Variance thresholding was also considered, but it only dropped a small number of features given the sparsity of the data.\n",
    "\n",
    "2000 features was chosen arbitrarily to balance ease of working with the dataset with retaining enough information for classification."
   ],
   "id": "c3febe1e0c15f7b3"
  },
  {
   "cell_type": "code",
   "id": "a2619f43",
   "metadata": {},
   "source": "mi = mutual_info_classif(X, Y, discrete_features=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mi_id_sort = np.argsort(mi)\n",
    "top_idx = mi_id_sort[-2000:]\n",
    "X_reduced = X.iloc[:, top_idx]"
   ],
   "id": "3e3c01217f5fa816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, Y_train, Y_test = train_test_split(X_reduced, Y, test_size=0.2, random_state=31415)",
   "id": "c4fa67fa64783781",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a78ee0ceb5622dd",
   "metadata": {},
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "evaluate_model(random_forest, X_train, Y_train, X_test, Y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initial results show the random forest is performing well. The minority class is performing the worst and is often being confused with the majority class, which is expected, but is still being classified reasonably well.",
   "id": "c2960ed9efbd8851"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can try a few different techniques to see if we can improve performance further. First, we can try increasing the number of estimators in the random forest to attempt to reduce the overfitting.",
   "id": "fbb9fede576f4f7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "evaluate_model(random_forest, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "7bc9a4e44dd683bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next we can try to introduce balanced class weights to help the model pay more attention to the minority class.",
   "id": "62768631403f836e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=1)\n",
    "evaluate_model(random_forest, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "774213fcc14c2800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neither technique provided a significant improvement over the original random forest model. Next we can try a different model entirely and see how it performs.",
   "id": "aa99c5e819b0b4f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000, random_state=1)\n",
    "evaluate_model(logistic_regression, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "7f67f983be8389ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Logistic regression is performing similarly to the random forest, but slightly better on the minority class. There is a similar pattern of misclassification, so it is likely that the features being used are not sufficient to fully separate the classes. Let's try with more features.",
   "id": "d4a635e907410501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_idx = mi_id_sort[-6000:]\n",
    "X_reduced_6k = X.iloc[:, top_idx]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_reduced_6k, Y, test_size=0.2, random_state=31415)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "evaluate_model(random_forest, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "1b094152366c10e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tripling the number of features didn't change performance, indicating that the original 2000 features captured most of the useful information for classification. We can also try reducing the number of features to see how low we can go before performance degrades.",
   "id": "ab081bb958a4cfbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_results = {\"num_features\": [], \"balanced_train\": [], \"balanced_test\": [], \"f1_train\": [], \"f1_test\": []}\n",
    "for num_features in range(2000, 0, -200):\n",
    "    print(f\"Evaluating with top {num_features} features\")\n",
    "    top_idx = mi_id_sort[-num_features:]\n",
    "    X_reduced_n = X.iloc[:, top_idx]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_reduced_n, Y, test_size=0.2, random_state=31415)\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    random_forest.fit(X_train, Y_train)\n",
    "\n",
    "    predictions_train = random_forest.predict(X_train)\n",
    "    metrics_train = score(predictions_train, Y_train)\n",
    "\n",
    "    predictions_test = random_forest.predict(X_test)\n",
    "    metrics_test = score(predictions_test, Y_test)\n",
    "\n",
    "    metrics_results[\"num_features\"].append(num_features)\n",
    "    metrics_results[\"balanced_train\"].append(metrics_train[\"balanced accuracy\"])\n",
    "    metrics_results[\"balanced_test\"].append(metrics_test[\"balanced accuracy\"])\n",
    "    metrics_results[\"f1_train\"].append(metrics_train[\"f1\"])\n",
    "    metrics_results[\"f1_test\"].append(metrics_test[\"f1\"])"
   ],
   "id": "62283beedf1773ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot results\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Balanced accuracy\n",
    "axes[0].plot(metrics_results[\"num_features\"], metrics_results[\"balanced_train\"], marker=\"o\", label=\"Train\")\n",
    "axes[0].plot(metrics_results[\"num_features\"], metrics_results[\"balanced_test\"], marker=\"o\", label=\"Test\")\n",
    "axes[0].set_xlabel(\"Number of features (top k)\")\n",
    "axes[0].set_ylabel(\"Balanced accuracy\")\n",
    "axes[0].set_title(\"Balanced Accuracy vs Number of Features\")\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].legend()\n",
    "\n",
    "# F1\n",
    "axes[1].plot(metrics_results[\"num_features\"], metrics_results[\"f1_train\"], marker=\"o\", label=\"Train\")\n",
    "axes[1].plot(metrics_results[\"num_features\"], metrics_results[\"f1_test\"], marker=\"o\", label=\"Test\")\n",
    "axes[1].set_xlabel(\"Number of features (top k)\")\n",
    "axes[1].set_ylabel(\"F1 (weighted)\")\n",
    "axes[1].set_title(\"F1 (weighted) vs Number of Features\")\n",
    "axes[1].invert_xaxis()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "f26b278dff8083cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The performance of the model is very stable down to 200 features with the variation likely due to random chance from the train/test split. This indicates that a small number of genes are sufficient to accurately classify the cell types in this dataset. We will see how far we can reduce the feature set while maintaining good performance.",
   "id": "f0734f0031a26630"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_results = {\"num_features\": [], \"balanced_train\": [], \"balanced_test\": [], \"f1_train\": [], \"f1_test\": []}\n",
    "for num_features in range(200, 0, -10):\n",
    "    print(f\"Evaluating with top {num_features} features\")\n",
    "    top_idx = mi_id_sort[-num_features:]\n",
    "    X_reduced_n = X.iloc[:, top_idx]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_reduced_n, Y, test_size=0.2, random_state=31415)\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    random_forest.fit(X_train, Y_train)\n",
    "\n",
    "    predictions_train = random_forest.predict(X_train)\n",
    "    metrics_train = score(predictions_train, Y_train)\n",
    "\n",
    "    predictions_test = random_forest.predict(X_test)\n",
    "    metrics_test = score(predictions_test, Y_test)\n",
    "\n",
    "    metrics_results[\"num_features\"].append(num_features)\n",
    "    metrics_results[\"balanced_train\"].append(metrics_train[\"balanced accuracy\"])\n",
    "    metrics_results[\"balanced_test\"].append(metrics_test[\"balanced accuracy\"])\n",
    "    metrics_results[\"f1_train\"].append(metrics_train[\"f1\"])\n",
    "    metrics_results[\"f1_test\"].append(metrics_test[\"f1\"])"
   ],
   "id": "e06911794e920155",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot results\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Balanced accuracy\n",
    "axes[0].plot(metrics_results[\"num_features\"], metrics_results[\"balanced_train\"], marker=\"o\", label=\"Train\")\n",
    "axes[0].plot(metrics_results[\"num_features\"], metrics_results[\"balanced_test\"], marker=\"o\", label=\"Test\")\n",
    "axes[0].set_xlabel(\"Number of features (top k)\")\n",
    "axes[0].set_ylabel(\"Balanced accuracy\")\n",
    "axes[0].set_title(\"Balanced Accuracy vs Number of Features\")\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].legend()\n",
    "\n",
    "# F1\n",
    "axes[1].plot(metrics_results[\"num_features\"], metrics_results[\"f1_train\"], marker=\"o\", label=\"Train\")\n",
    "axes[1].plot(metrics_results[\"num_features\"], metrics_results[\"f1_test\"], marker=\"o\", label=\"Test\")\n",
    "axes[1].set_xlabel(\"Number of features (top k)\")\n",
    "axes[1].set_ylabel(\"F1 (weighted)\")\n",
    "axes[1].set_title(\"F1 (weighted) vs Number of Features\")\n",
    "axes[1].invert_xaxis()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "e0178e42a61cd47e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Performance is stable all the way down to 20 features. This indicates that there are a small number of genes that are highly informative for distinguishing the cell types in this dataset. We can have a look at the performance of the logistic regression model using only these top 20 features.",
   "id": "42a77b8d5d828748"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_reduced_n = X.iloc[:, mi_id_sort[-20:]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_reduced_n, Y, test_size=0.2, random_state=31415)\n",
    "logistic_regression = LogisticRegression(max_iter=1000, random_state=1)\n",
    "evaluate_model(logistic_regression, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "ccd59867adda9cdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Test performance is unchanged even with only 20 features, indicating that these genes capture most of the useful information for classification. The model is overfitting less with fewer features, as expected.\n",
    "Let's have a look at which genes were selected as the most informative."
   ],
   "id": "b6ad549ecf411775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genes = pd.DataFrame(logistic_regression.coef_[0], index=X_reduced_n.columns, columns=[\"coefficient\"]).sort_values(\n",
    "    by=\"coefficient\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=genes.index, y=genes[\"coefficient\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 20 Features by Logistic Regression Coefficient\")\n",
    "plt.xlabel(\"Gene\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.show()"
   ],
   "id": "f7385c9893d66ccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "evaluate_model(random_forest, X_train, Y_train, X_test, Y_test)"
   ],
   "id": "7fbfdf63f035a6be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genes = pd.DataFrame(random_forest.feature_importances_, index=X_reduced_n.columns, columns=[\"importance\"]).sort_values(\n",
    "    by=\"importance\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=genes.index, y=genes[\"importance\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 20 Features by Random Forest Importance\")\n",
    "plt.xlabel(\"Gene\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ],
   "id": "6c23272a31772ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It seems like both models have similar importance on each gene, but we can visualize this better by plotting the importance from the random forest against the coefficient from the logistic regression.\n",
    "Note that we take the absolute value of the logistic regression coefficients, as the sign only indicates the direction of the effect, not the magnitude."
   ],
   "id": "bd8c7239b96e6876"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined = genes.join(\n",
    "    pd.DataFrame(abs(logistic_regression.coef_[0]), index=X_reduced_n.columns, columns=[\"coefficient\"]))\n",
    "combined"
   ],
   "id": "6ab6a03fa42b4bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"importance\", y=\"coefficient\", data=combined)\n",
    "for i in combined.index:\n",
    "    plt.text(combined.loc[i, \"importance\"], combined.loc[i, \"coefficient\"], i)\n",
    "plt.title(\"Feature Importance vs Coefficient\")\n",
    "plt.xlabel(\"Random Forest Importance\")\n",
    "plt.ylabel(\"Logistic Regression Coefficient\")\n",
    "plt.show()"
   ],
   "id": "d7a78251c22cda95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The low importance/coefficient genes are clustered together, while the high importance/coefficient genes show more variation between the two models, indicating that they are capturing different aspects of the data. Notably, the random forest seems like a smoother importance distribution, while the logistic regression has a few genes with very high coefficients and the rest much lower. This is likely due to the fact that the random forest can capture more complex relationships between features, while the logistic regression is limited to linear relationships.",
   "id": "ca65882a8f8753f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also visualise how the cell types are distributed in lower dimensional space. To get a better idea of how the types are separated.",
   "id": "fbb8d9a96f329fb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sc.pp.pca(data, n_comps=50)\n",
    "sc.pp.neighbors(data, n_neighbors=10, n_pcs=50)\n",
    "sc.tl.umap(data)\n",
    "sc.pl.umap(data, color=\"cell-types\")"
   ],
   "id": "696f9e349cc82a3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The clusters seem to be fairly well separated. It is a bit hard to see without zooming in, but there is a non-trivial amount of the minority class (Dendritic cells) that overlaps with the majority class, which likely contributes to the misclassifications we are seeing.",
   "id": "be0c750cd49d0515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_data = anndata.read_h5ad('data/Test_dataset.h5ad')",
   "id": "4c749da46f8341e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define some dicts to assist in converting values",
   "id": "6376c58f91a0846c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gene_id_mapping = {\"ENSG00000115523\": \"GNLY\",\n",
    "                   \"ENSG00000105374\": \"NKG7\",\n",
    "                   \"ENSG00000204287\": \"HLA-DRA\",\n",
    "                   \"ENSG00000019582\": \"CD74\",\n",
    "                   \"ENSG00000100453\": \"GZMB\",\n",
    "                   \"ENSG00000011600\": \"TYROBP\",\n",
    "                   \"ENSG00000077984\": \"CST7\",\n",
    "                   \"ENSG00000196126\": \"HLA-DRB1\",\n",
    "                   \"ENSG00000223865\": \"HLA-DPB1\",\n",
    "                   \"ENSG00000198502\": \"HLA-DRB5\",\n",
    "                   \"ENSG00000007312\": \"CD79B\",\n",
    "                   \"ENSG00000105369\": \"CD79A\",\n",
    "                   \"ENSG00000167526\": \"RPL13\",\n",
    "                   \"ENSG00000145649\": \"GZMA\",\n",
    "                   \"ENSG00000231389\": \"HLA-DPA1\",\n",
    "                   \"ENSG00000227507\": \"LTB\",\n",
    "                   \"ENSG00000140988\": \"RPS2\",\n",
    "                   \"ENSG00000137441\": \"FGFBP2\",\n",
    "                   \"ENSG00000137154\": \"RPS6\",\n",
    "                   \"ENSG00000144713\": \"RPL32\"}\n",
    "\n",
    "cell_type_mapping = {\n",
    "    \"CD8+ T cell\": \"CD8+/CD45RA+\",\n",
    "    \"CD4+ T cell\": \"CD8+/CD45RA+\",\n",
    "    \"Other T\": \"CD8+/CD45RA+\",\n",
    "    \"B cell\": \"CD19+ B\",\n",
    "    \"Plasmablast\": \"CD19+ B\",\n",
    "    \"NK cell\": \"CD56+ NK\",\n",
    "    \"cDC\": \"Dendritic\",\n",
    "    \"pDC\": \"Dendritic\",\n",
    "    \"CD14+ Monocyte\": \"ignored\",\n",
    "    \"CD16+ Monocyte\": \"ignored\",\n",
    "    \"Platelet\": \"ignored\"\n",
    "}"
   ],
   "id": "fbd0ce019038146d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df = pd.DataFrame(test_data.X.toarray(), columns=test_data.var_names.tolist())\n",
    "test_df"
   ],
   "id": "9865759250db2147",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reduce our dataset down to only the 20 genes we are interested in",
   "id": "5557ab83438733db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reduced_test_df = test_df[gene_id_mapping.keys()]\n",
    "reduced_test_df"
   ],
   "id": "da474a8e9162402e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setting up dataset for prediction",
   "id": "f479c3ea95e4ab3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Y = test_data.obs[\"cell-types\"]\n",
    "Y.value_counts()"
   ],
   "id": "bbf7313c59686cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loop through the Y list and map each to their pre-decided cell type from the training set\n",
    "Y_adjusted = [(lambda x: cell_type_mapping[x])(x) for x in Y]\n",
    "# rename the dataset columns to their gene names used during training and reorder them\n",
    "X = reduced_test_df.rename(gene_id_mapping, axis=1)[X_train.columns.tolist()]"
   ],
   "id": "4549443c791c2dfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a 'mask' of the rows to keep or remove\n",
    "mask = pd.Series(Y_adjusted) != 'ignored'\n",
    "Y_original = pd.Series([x[0] for x in zip(Y, mask) if x[1]])\n",
    "X = X[mask.values]\n",
    "Y_adjusted = pd.Series(Y_adjusted)[mask]"
   ],
   "id": "bf632ad53d7f5392",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions = random_forest.predict(X)",
   "id": "9cbb091ac5b0c931",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(score(predictions, Y_adjusted))\n",
    "\n",
    "cm = confusion_matrix(Y_adjusted, predictions, labels=random_forest.classes_, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=random_forest.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "id": "c0a04f4a2ab864ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets have a look at this breakdown per original label",
   "id": "9dbdc10b2a57f142"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "original_label_mapping = defaultdict(list)\n",
    "for pred, orig in zip(predictions, Y_original):\n",
    "    original_label_mapping[orig].append(pred)"
   ],
   "id": "987e5ead804fb9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cell_type_mapping",
   "id": "99fc1990d42745be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, key in enumerate(original_label_mapping.keys()):\n",
    "    counts = pd.Series(original_label_mapping[key]).value_counts()\n",
    "    heights = counts / counts.sum()\n",
    "    palette = {c: \"red\" if c != cell_type_mapping[key] else \"green\" for c in random_forest.classes_}\n",
    "\n",
    "    sns.barplot(x=heights.index, y=heights.values, order=random_forest.classes_, palette=palette, ax=ax[i])\n",
    "\n",
    "    ax[i].set_title(key)\n",
    "    ax[i].tick_params(axis='x', rotation=20)\n",
    "    ax[i].set_ylabel(\"Proportion\")\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "7e8a671eaba64e4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T12:17:49.975068Z",
     "start_time": "2025-10-20T12:17:49.973876Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "The Dendritic cells and CD59+ NK cells are being consistently classified correctly with almost no mistakes in their new cell types.\n",
    "The other two categories have at least one new cell type that they perform poorly on. Notably there seems to be a significant amount of noise in the CD8+ types, with two of the new types being ~50% classified as NK and the third being mostly correct but with a large portion of dendritic."
   ],
   "id": "22789a6c265c9309"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = logistic_regression.predict(X)\n",
    "print(score(predictions, Y_adjusted))\n",
    "\n",
    "cm = confusion_matrix(Y_adjusted, predictions, labels=random_forest.classes_, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=random_forest.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "original_label_mapping = defaultdict(list)\n",
    "for pred, orig in zip(predictions, Y_original):\n",
    "    original_label_mapping[orig].append(pred)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, key in enumerate(original_label_mapping.keys()):\n",
    "    counts = pd.Series(original_label_mapping[key]).value_counts()\n",
    "    heights = counts / counts.sum()\n",
    "    palette = {c: \"red\" if c != cell_type_mapping[key] else \"green\" for c in random_forest.classes_}\n",
    "\n",
    "    sns.barplot(x=heights.index, y=heights.values, order=random_forest.classes_, palette=palette, ax=ax[i])\n",
    "\n",
    "    ax[i].set_title(key)\n",
    "    ax[i].tick_params(axis='x', rotation=20)\n",
    "    ax[i].set_ylabel(\"Proportion\")\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "a1d8c4cef00536e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Logistic regression achieves very similar results as expected by their similarity in training. The results to tend slightly worse on the classes random forest was doing poorly on.",
   "id": "fbe15317426ce642"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Interestingly, there seems to be a relatively high degree of misclassification towards Dendritic in both cases which may be a consequence of overfitting for the minority class during training. This is also reinforced by the high performance of the Dendritic cells.",
   "id": "5db27f2c70f50d91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
